{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14eCcs3LMPkr"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "fid = drive.ListFile({'q':\"title='flower.zip'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('flower.zip')\n",
        "f.keys()\n",
        "!unzip flower.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnI_xtn0MvTa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHTOH5V3MvKW"
      },
      "outputs": [],
      "source": [
        "dataset = '/content/flower'\n",
        "\n",
        "#test_dir ='/content/BHDN'\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywU4vUHeMvG-"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.keras.utils.image_dataset_from_directory(dataset,\n",
        "                                                                 shuffle=True,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 image_size=IMG_SIZE,\n",
        "                                                                 validation_split=.20,\n",
        "                                                                 subset='training',\n",
        "                                                                 seed=66)\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(dataset,\n",
        "                                                                 shuffle=True,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 image_size=IMG_SIZE,\n",
        "                                                                 validation_split=.20,\n",
        "                                                                 subset='validation',\n",
        "                                                                 seed=66)\n",
        "#test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
        "#                                                                shuffle=True,\n",
        "#                                                                batch_size=BATCH_SIZE,\n",
        "#                                                                image_size=IMG_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNkReiteMvDc"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomFlip(\"horizontal\"),\n",
        "     layers.RandomRotation(0.1),\n",
        "     layers.RandomContrast(factor=0.1),\n",
        "     layers.RandomBrightness(factor=0.1),\n",
        "\n",
        "        layers.RandomZoom(height_factor=0.1, width_factor=0.1),\n",
        "\n",
        "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "\n",
        "\n",
        "     ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0J0jZshHMvAp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "for images, labels in train_dataset.take(1):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    first_image = images[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        augmented_image = data_augmentation(\n",
        "            tf.expand_dims(first_image, 0), training=True\n",
        "        )\n",
        "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
        "        plt.title(int(labels[0]))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ww1JYCBMu-C"
      },
      "outputs": [],
      "source": [
        "base_model = keras.applications.VGG16 (\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        ")  # Do not include the ImageNet classifier at the top.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65KEvySQMu7L"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbDcbtzdMu4e"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwGQkXtdMuyo"
      },
      "outputs": [],
      "source": [
        "nb_classes = 24\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
        "# outputs: `(inputs * scale) + offset`\n",
        "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
        "x = scale_layer(x)\n",
        "\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "outputs = Dense(nb_classes, activation=\"softmax\")(x)\n",
        "#outputs = keras.layers.Dense(13)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "modelF = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6OsIh__MuwV"
      },
      "outputs": [],
      "source": [
        "callback=tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=1e-4,\n",
        "    patience=5,\n",
        "    verbose=0,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        "    start_from_epoch=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdAtbcbSMutZ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam' , loss='sparse_categorical_crossentropy',metrics =['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzi2TbsUMuqx"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "history = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset,callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jed6m97lMunv"
      },
      "outputs": [],
      "source": [
        "#scores = model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "edWPrSRszqQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVJz7kR2Muk3"
      },
      "outputs": [],
      "source": [
        "modelF.trainable = True\n",
        "modelF.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFLaU1MjMuiP"
      },
      "outputs": [],
      "source": [
        "modelF.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics =['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9ibRAuqMufu"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "modelF.fit(train_dataset, epochs=epochs, validation_data=validation_dataset,callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(modelF)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model1.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "ns61isO3tYNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your Google Drive folder\n",
        "drive_folder = '/content/drive/My Drive/flower/'\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "import os\n",
        "if not os.path.exists(drive_folder):\n",
        "    os.makedirs(drive_folder)\n",
        "\n",
        "# Path to save the TFLite model in your Google Drive folder\n",
        "tflite_model_path = os.path.join(drive_folder, 'model.tflite')\n",
        "\n",
        "# Save the TFLite model to the specified path\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f'TFLite model saved to: {tflite_model_path}')\n"
      ],
      "metadata": {
        "id": "8CTyHMiNtdQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjM3LD4yMuc8"
      },
      "outputs": [],
      "source": [
        "#scores = modelF.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpdPDBOnMuZx"
      },
      "outputs": [],
      "source": [
        "class_names = validation_dataset.class_names\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjX8Idb5MuWu"
      },
      "outputs": [],
      "source": [
        "def predict(modelF, img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "    predictions = modelF.predict(img_array)\n",
        "\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "    return predicted_class, confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f9IEvWyMuTh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for images, labels in validation_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "        predicted_class, confidence = predict(modelF, images[i].numpy())\n",
        "        actual_class = class_names[labels[i]]\n",
        "\n",
        "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
        "\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "validation_dataset = validation_dataset.unbatch().batch(1)  # Batch size = 1 for individual predictions\n",
        "\n",
        "# Replace 'Class 0' and 'Class 1' with the actual class names from your dataset\n",
        "\n",
        "# Create empty arrays to store true labels and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Iterate through the validation dataset to obtain true and predicted labels\n",
        "for images, labels in validation_dataset:\n",
        "    predictions = model.predict(images)\n",
        "    predicted_labels.extend(np.argmax(predictions, axis=1))\n",
        "    true_labels.extend(labels.numpy())\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Create a heatmap using seaborn\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
        "\n",
        "# Add a title and axis labels\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e3PJLMmW1xRE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}